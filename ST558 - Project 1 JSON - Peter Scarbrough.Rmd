---
title: ST558 - Project 1 - JSON Vignette
author: Peter Scarbrough
date: October 16, 2019
output: 
  html_document:
    toc: true
    toc_float: true
---

*This vignette is designed to introduce the JSON file format and explore how to work with it in R.*

# JSON File Format  

The [JSON](https://en.wikipedia.org/wiki/JSON) file format was first created by Douglas Crockford in the early 2000s using [Javascript](https://en.wikipedia.org/wiki/JavaScript) as a means for storing internet data. Eventually the file format became a standardized Javascript object and given Javascript's position as the *de facto* official scripting language of the internet, it wasn't long before JSON became one of the most widely used formats for sharing data by websites and APIs (e.g. [Twitter API](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json)). As a result, by now most programming languages have packages that allow the reading and creation of JSON files.  

The JSON file format is a hierarchical data format that may be used as an alternative to [XML](https://en.wikipedia.org/wiki/XML). In this format, data are stored with key-value pairs using [strong typing](https://en.wikipedia.org/wiki/Strong_and_weak_typing). Strong typing basically means the variables are defined as having a type (e.g. integer, character) and once they are defined with a type they keep that type. The key-value pairing is a convenient and intuitive use of syntax to define the values for a variable. These features of JSON contrast with the XML file format which defines data using tags and employs weak-typing. In general, this makes JSON a little easier to work with than XML.

JSON files can represent a simple 2D data set.

```{r json.code.example1, eval=F} 
{  
  {  
    "name": "Darth Vader"  
    "age" : 60  
    "occupation": "Sith Lord"  
  },  
  {  
    "name": "Luke Skywalker"  
    "age": 40  
    "occupation": "Jedi Master"  
  }  
} 
```

JSON files can contain keys with nested, hierarchical data.

```{r eval=F} 
{  
  "name": "Darth Vader"  
  "age": 60  
  "occupation": "Sith Lord"  
  "episodes": [3, 4, 5, 6]  
  "relationships": [  
      "Luke Skywalker": "Son",  
      "Leia Organa": "Daughter"  
  ]  
}  
```

Dealing with this hierarchical structure is probably the most challenging thing when working with file formats like JSON or XML. Fortunately, there are packages in R that can help simplify this task for us. Although there is no way for R to automatically generate tidy datasets when reading JSON data, there are functions in R that can automatically coerse JSON objects into data frames of atomic vectors, lists, and potentially other data frames.

# JSON Packages in R

There are 3 main packages for reading JSON files in R.

1) [rjson](https://cran.r-project.org/web/packages/rjson/rjson.pdf)  
2) [RJSONIO](https://cran.r-project.org/web/packages/RJSONIO/RJSONIO.pdf)  
3) [jsonlite](https://rdocumentation.org/packages/jsonlite/versions/1.6)  

All packages will attempt to open, parse, and simplify a JSON file into the relevant R objects. The packages mostly differ on implementation details and with available features and options. In general `rjson` are `RJSONIO` are theoretically more light-weight than `jsonlite`, they have fewer features but  sometimes have the advantage of speed and simplicity. `RJSONIO` differs from `rjson` in that it uses the C++ library, `libjson`, to parse JSON files, instead of parsing with R code, which gives it a potential advantage in speed. 

The `jsonlite` package was originally developed as a fork from `RJSONIO` to add additional features such as interfacing with APIs, compatibility with `tidyverse` pipelines, ability to read streaming JSON data, along with greater capacity to check for data type errors, better handling of missing data, and better routines to handle JSON simplification and nested data frame flattening. Of course, along with all of these features comes additional overhead and so `jsonlite` tends to be a little bit slower with the upside that reading and writing JSON files will be a bit more intuitive, automatic, and accurate. *Since I am valuing features and accuracy over speed, I have chosen to use `jsonlite` in the following example.*

## Key functions in `jsonlite`

The `jsonlite` package contains a number of internal functions that are mostly intended for internal use - one can consult the [documentation](https://www.rdocumentation.org/packages/jsonlite/versions/1.6) for more information. Otherwise, most users probably need only concern themselves with the following key functions:  

Function | Description
-----|-----
`fromJSON` | Reads JSON data from file path or character string, automatically converting and simplifying to an R object    
`toJSON` | Converts R object to JSON object  
`read_json` | Same as `fromJSON` except only accepts file path and does not simplify by default    
`write_json` | Same as `toJSON` except only accepts file path and does not simplify by default   
`stream_in` | Accepts a *file connection* (e.g. file("filename")) as an argument. Necessary for reading in streaming JSON data and end-line delimited JSON (NDJSON) file formats.

## Key Features in `jsonlite::read_json`   

The `read_json` function is essentially the workhorse of the `jsonlite` package that comes with the following important options.

Feature | Default | Description
-----|-----|-----
simplifyVector | TRUE | Simplifies JSON primative-only arrays to an atomic vector
simplifyDataFrame | TRUE | Simplifies JSON-only-objects to a data frame
simplifyMatrix | TRUE | Simplifies JSON equal mode and dimension arrays to matrix
flatten | FALSE | Automatically flattens nested data frames to non-nested

Without these simplifications, the returned JSON object will essentially contain more objects wrapped in lists that the user will then have to manually unwrap with code. The flatten argument is set to `FALSE` likely because automating the process by default has the possibility to introduce more errors. In general, it is best to load a minimally modified object and figure out what the structure is and then simplify from that. Fortunately, the arguments in the `fromJSON` file are reasonably safe assumptions. *Therefore, in the following example, the default options will be accepted when reading in the data.*

# Example JSON Data Set

I will download the following data set to further explore JSON file formats and data analysis in R. This data was chosen as an example JSON format because it is relatively easy to understand in concept and because it's structure is fairly simply to get started. As far as JSON data goes, it's fairly simple: containing mostly atomic vectors of categorical and quantitative data with nested data structures in only a few columns.

## Metadata

Feature | Description
-----|-----
Data | **GOG Games with Reviews**   
Filename | "games.json"  
Repository | [kaggle](https://www.kaggle.com)  
URL | [https://www.kaggle.com/beastovest/gog-games-with-reviews](https://www.kaggle.com/beastovest/gog-games-with-reviews)   
Download Date | October 10, 2019  
Description | This data set is a collection of player and critic review data for computer video games (along with meta information about these games) from the website: www.gog.com. [GOG](https://www.gog.com) is a website where people can purchase and download computer games from a variety genres and publishers. Their catelog of video games spans many hundreds of titles released over the last few decades.
Source | Web-scraping of GOG.com  
Dimensions | 2742 rows, 23 columns  

## Variables

Label | Variable Name | Description | Type 
-----|-----|-----|-----
URL | url | Game website on GOG.com | character
Name | name | Name of Game | character
Price in USD | price | Price of Game | double
Player Rating | player_rating | Average Player Rating (1-5) | double
Genres | genres | Genres Applicable to Game | 1 item list: character array
Operation Systems | oses | OS Compatible with Game | 1 item list: character array
Size | size | Hard Drive Space | character
Rating | rating | Maturity Rating of Game (PEGI Scores) | character
Release Date| release_date | Game Release Date | character
Developer | developer | Developer | character
Publisher | publisher | Publisher | character
Cloud Saves | cloud_saves | Has Cloud Saves | logical
Controller Support | controller_support | Has Controller Support | logical
Overlay | overlay | Has GOG Overlay | logical
Single Player | single_player | Is Single Player | logical
Achievement | achievement | Has achievements | logical
Multiplayer | multi_player | Is Multiplayer | logical
Coop | coop | Has Co-op | logical
Leaderboard | leaderboard | Has Leaderboard | logical
In Development | in_development | In Development | logical
Languages | languages | Supported Languages | 3 item data frame  
Achievements | achievements | Achievements In Game | 3 item data frame
Reviews | reviews | Player Reviews | 8 item data frame  

## Nested Data Structures

### Languages

Label | Variable Name | Description | Type 
-----|-----|-----|-----
Name | name | Name of Language | character
Text | text | Text is translated | logical
Audio | audio | Audio is translated | logical

### Achievements

Label | Variable Name | Description | Type 
-----|-----|-----|-----
Name | name | Name of Achievement | character
Description | description | Description of Achievement | character
Rarity | rarity | Rarity of Achievement | double

### Reviews   

Label | Variable Name | Description | Type 
-----|-----|-----|-----
Name | name | Name of Reviewer | character
Count | count | Count | double 
Reivews Count | reviews_count | # of Reviews by Reviewer | double
Verified Owner | verified_ower | Verified Owner of Game | logical
Rating | rating | Rating of Game (1 poor - 5 good) | double
Creation Date | creation_date | Date Review was Made | character
Title | title | Title of Review | character
Content | content | Full Text Review | character

## Loading the Data

The data will be loaded using the `fromJSON` function from the `jsonlite` package. This function uses the same read-in function name as `rjson` and `RJSONIO` which allows users to more easily reuse code even if they are switching packages. The function contains the required argument `txt` which must specify either raw JSON text or a path to a JSON file. The `fromJSON` function also offers more *features* that the `read_json` function which allow for control over how the JSON object is simplified. However, since these data appear safe to simplify and `read_json` does not simplify by default, this is another reason to use the `fromJSON` function in this case.

### Using `fromJSON`

```{r load.data, message=F, warning=F}
# Load required packages
library(tidyverse)  # for data manipulation
library(knitr)      # for r markdown functions
library(jsonlite)   # for JSON file

# setting global r markdown options
opts_chunk$set(message=F, warning=F)

# Load Data
myData <- fromJSON("games.json")
```

### Checking Structure

Once loaded, the data is checked for being correctly loaded and looking as expected. The first few rows of data are printed and the size of each column in the data set is calculated.

```{r check structure}
# Print a few rows of the data to inspect structure, ensure properly loaded
library(DT)
datatable(head(myData), options = list(scrollY="400px", scrollX='400px'))

# Getting names and column size
sapply(myData, function(x) format(object.size(x), units="Mb"))
```

As we can see, the data appear to have loaded correctly and seem to contain expected information. As expected, the JSON data is far from tidy, containing various nested data structures (e.g. `genres`). It would be possible to tidy the entire dataset, but we will consider our analysis goals first in order to determine exactly what data we need to tidy, in order to make sure we don't waste our time. Note that most of the file size is only due to 3 columns: `languages`, `achievements` and `reviews`. These are due to nested data frames that contain large amounts of text (not shown). 

# Analysis of JSON Data

*Note: For the purpose of this analysis `price` and `player_rating` will be treated as quantitative variables and all other variables will be considered as categorical variables.*

## Analysis Goals

Determine how player ratings change as a function of genre, price, and publisher. Essentially this is to investigate what factors may influence consumer satisfaction. Whether a game is single or multiplayer will also be considered. Multivariate plots will be constructed to look at possible interactions bewteen player ratings and the indicated variables. Since there are many categories of publisher and genre, this preliminary analysis will focus on a simplified approach that restricts analysis only the top 5 gaming genres and top 15 game publishers. These cutoff points were chosen arbitrarily. 

## Preparing the data

As a first step in preparing the data, I will remove all variables not of interest. This will keep player rating, price and publisher variables, the single- and multi-player indicator variables, as well as the nested variable that contains information of which genres the game belongs to. 

```{r trim.data}
# ***trim data***
# keep only relevant columns
myData <- myData %>%
  select(player_rating, genres, price, publisher, single_player, multi_player)
```

Next, I will need to pull out genre data from the nested JSON structure and use this to create a more tidy data frame. **To do this, I will construct a custom function, `tidySimpleList`, and then use that function to generate new variables.** 

```{r tidy.data.genre}
# (i) create custom function to parse nested simple list data into logical columns
#     arguments:
#       - data = data frame
#       - simpleListCol = name of column that contains nested 
#                         lists of length one (char arrays)
#       - prefix = specify prefix to give when creating new column names

tidySimpleList <- function(data, simpleListCol, prefix=""){
  # (iia) get unique column names from parsed nested simple list
  uniqueNames <- unique(unlist(data[[simpleListCol]]))
  newVarNames <- paste0(prefix, uniqueNames)

  # (iib) add unique columns to data set
  for(j in newVarNames){
    data[[j]] <- logical(nrow(data))
  }
 
  # (iic) populate new columns (parse nested list data)
  for(i in 1:nrow(data)){
    listContents <- unlist(data[[simpleListCol]][i])  # parse nested data
    changeCols   <- paste0(prefix, listContents)      # use to generate col names
    for(j in changeCols){
      data[[j]][i] <- TRUE                            # change ith row of col name to TRUE
    }  
  }
  
  return(data)
}

# (iii) use custom function to tidy genre data
myData <- tidySimpleList(myData, "genres", prefix="genre")

# (iv) remove nested data (genre column)
myData <- select(myData, -genres)

# (v) print first few rows of data to check results
#     note genre column now converted into logical indicator columns
datatable(head(myData), options = list(scrollY="400px", scrollX="400px"))
```

For a preliminary analysis, there are probably too many genres categories to consider. Therefore, I will restrict further analysis to only the top 5 gaming genres. To do this, I will create a data table of genre sums, sort it, take the list of bottom genres and remove those genres from the main data table. This will include removing all the indicated genre indicator columns as well as any game from the data set that is not a member of at least one of the top 5 genres. 

```{r remove.bottom.genres} 
# (i) get genre sums
genreSums <- myData %>% 
  select(contains("genre")) %>% 
  colSums() %>%
  as.data.frame()

# (ii) add column for genre names, arrange by counts, select top genres
genreSums$genre     <- rownames(genreSums)
rownames(genreSums) <- NULL
names(genreSums)[1] <- "count"
genreSums <- arrange(genreSums, desc(count))
print(head(genreSums))                              # checking temp result
topGenres <- genreSums$genre[1:5]                   # store top genres
bottomGenres <- genreSums$genre[6:nrow(genreSums)]  # store bottom genres

# (iii) remove bottom genre columns
myData <- myData %>% 
  select(-bottomGenres)

# (iv) remove games (rows) not within top 5 genres
#      note: removing if sum of top 5 genre indicators is not greater than 0
myData <- myData %>%
  mutate(top5Sums = rowSums(myData[,6:10])) %>%
  filter(top5Sums > 0) %>%
  select(-top5Sums)
```

Next, to further simplify this preliminary analysis into something more manageable, I will restrict further analysis to only consider data from the top 15 game publishers in the GOG.com data set. To do this, I will create a table of publisher counts, sort, store the bottom publisher data and finally use that data to filter the primary data set.

```{r tidy.data.publishers}
# (i) get counts of game by publisher
publisherCounts <- as.data.frame(table(myData$publisher)) %>% arrange(desc(Freq))

# (ii) get array of top and bottom publishers
topPubs <- publisherCounts$Var1[1:15]
botPubs <- publisherCounts$Var1[16:length(publisherCounts)]

# (iii) remove bottom publishers from data
myData <- filter(myData, publisher %in% botPubs)
```

Finally, as a last step in preparing the data (cleaning and tidying), and rows containing missing values (-1) for player rating or price will be removed from the data set and excluded from further analysis.

```{r remove missing data}
# remove missing (-1) price and rating data
myData <- myData %>%
  filter(player_rating != -1 & price != -1)
```

The data have been prepared and are now ready for analysis. The final prepared data is shown below:

```{r prepared.data}
# print of full, cleaned, tidy data set
datatable(myData, options=list(scrollY="400px", scrollX="400px"))
```

Now that the data have been cleaned and tidied, I will use this data and `ggplot2` in the next sections to conduct my preliminary analyses of the data. The goal will be to make some multivariate plots and try to draw preliminary inferences on what possible relationships might exist between player rating and other variables in data. 

## Exploratory Data Analysis  

An exploratory data analysis will be performed to check the single variable distributions and properties of the variables of interest in the data set in order to help validate the data and check for errors or other potentially interesting features of interest. 

### Quantitative Variables

Numerical summaries and histograms for quantitative variables is provided below.

```{r exp.data}

# (i) getting numerical summaries of data
# (ia) price
summary(myData$price) %>% 
  t() %>%
  as.data.frame() %>% 
  mutate(Value=round(Freq,2)) %>%
  select(-Var1,-Freq) %>%
  rename("Price"=Var2) %>%
  kable()
# (ib) player_rating
summary(myData$player_rating) %>%
  t() %>%
  as.data.frame() %>%
  mutate(Value=round(Freq,2)) %>%
  select(-Var1,-Freq) %>%
  rename("Player Rating"=Var2) %>%
  kable()

# assessing single variable features, distributions
# (ii) exploratory analysis - variables treated as quantitative
# (iia) price
ggplot(myData, aes(x=price)) + 
  geom_histogram(color="black", fill="green") + 
  labs(title="Histogram of Price",
       x="Price",
       y="Count")
# (iib) player_rating
ggplot(myData, aes(player_rating)) + 
  geom_histogram(color="black", fill="blue") + 
  labs(title="Histogram of Average Player Ratings",
       x="Average Player Rating",
       y="Count")
```

From these data we find that is a large variation in price and player rating. Player rating seems to be more of a skewed normal distribution than price data, which appears multi-modal. On inspection, both of these features appear to make sense. Pricing should have certain expected price points for games that likely occur more frequently than others, potentially explaining multi-modality. Player rating will also have floor and ceiling effects due to the limits in scale (1-5) within the rating, which likely explains the skewness in distribution. 

### Categorical Variables

Single-variable tables and contingency tables will be used to asses the counts for each level of the categorical variables in the data.

```{r exp.data2}
# (i) exploratory analysis - variables treated as categorical
# (ia) table, counts by genre
library(stringr)
genreNames <- str_remove(topGenres, "genre")
sapply(topGenres, function(Count) sum(myData[[Count]])) %>%
  as.data.frame() %>%
  mutate(Genre=genreNames) %>%
  rename(Count=".") %>%
  select(Genre, Count) %>%
  kable()

# (ib) table, counts by publisher
table(myData$publisher) %>% 
  as.data.frame() %>%
  rename(Publisher=Var1, Count=Freq) %>%
  arrange(desc(Count)) %>%
  kable()

# (ic) table, single-player and multi-player games
table(myData$single_player, myData$multi_player) %>%
  as.data.frame() %>%
  rename("Single-Player"=Var1, "Multi-Player"=Var2, "Count"=Freq) %>%
  kable()

# (ii) contingency table, genre x publisher
res <- sapply(topGenres, FUN=function(x){
         tapply(myData[[x]], myData$publisher, sum)
         }) %>%
       as.data.frame()
names(res) <- genreNames
kable(res)

# (iii) rework table of counts for plotting
res$Publisher <- rownames(res)
rownames(res) <- NULL
res           <- gather(res, names(res)[1]:names(res)[length(res)-1],
                        key="Genre",
                        value="Count")


# (iv) side-by-side bar plots - genre x publisher
ggplot(res, aes(x=Genre)) + 
  geom_bar(aes(y=Count), color="black", fill="green", stat="identity") + 
  facet_wrap(~Publisher) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title="Count of Genre by Publisher")
```

From these data we observe that top publishers tend to have reasonably diversified catelogs of game portfolios (appealing to multiple different genres), which makes sense given probable business needs. However, publishers appear to have specializations and differing distributions overall which suggests possible concern for confounding when attempting to relate player rating to either publisher or genre alone. 

Another interesting observation is that the contingency table of single-player versus multi-player games revealed that the GOG.com catalog of games offers no games that are exclusively multi-player after applying our filters to the data. Therefore, it makes sense to only focus on the `multi_player` variable as a lone contrast, since all games in this set of data appear to at least have a single-player component. This analysis strategy will be reflected by modification to the factor as shown below:

```{r multiplayer.mod}
myData$multi_player <- factor(myData$multi_player,
                              levels=c(F, T),
                              labels=c("No MultiPlayer", "Has MultiPlayer"))
```

## Analysis: Interactions with Player Rating

Since I am primarily interested in player rating as a response variable, the following breakdowns were made by `player_rating` to examine what kinds of direct effects on player rating may exist in the data set. To get 2-way data for the genre variable (currently spread out across logical columns), I will create a custom function, which returns the relevant data frame. This essentially lengthens the data set using the genre logical columns by the indicated column(s) of data.

```{r helper.function}
# will lengthen data by colNames key only if TRUE using targetCol values
longFromLogicals <- function(data, colNames, targetCols, key="key"){
  # initialize empty data frame
  dfResult          <- data.frame()
  dfResult[[key]]   <- character()
  for(col in targetCols){
    dfResult[[col]] <- numeric()
  }
  
  # by row, by logical column,
  #   if true: get value from targetCol, lengthen dfResult
  #   else: pass
  for(i in 1:nrow(data)){
    for(j in colNames){
      if(data[[j]][i]){
        tempList          <- list()
        tempList[[key]]   <- j
        for(col in targetCols){
          tempList[[col]] <- data[[col]][i] 
        }
        dfResult <- rbind.data.frame(dfResult, tempList, stringsAsFactors=F)
      }
    }
  }
  
  # return result
  dfResult
}
```

Next, I will plot several multivariate plots with player rating to investigate for the presence of potentially interesting relationships or observations worth further investigation.

```{r player.rating.interactions}
# (ia) box_plots: player rating by publisher
ggplot(myData, aes(x=publisher, y=player_rating)) + 
  geom_boxplot() + 
  labs(title="Box Plot of Average Player Rating by Publisher",
       x = "Publisher",
       y = "Average Player Rating") +
   theme(axis.text.x = element_text(angle = 90, hjust = 1)) 

# (ib) box_plots: player rating by publisher, broken down by multiplayer
ggplot(myData, aes(x=publisher, y=player_rating)) + 
  geom_boxplot() + 
  facet_wrap(multi_player~.,) + 
  labs(title="Box Plot of Average Player Rating by Publisher",
       x = "Publisher",
       y = "Average Player Rating") +
   theme(axis.text.x = element_text(angle = 90, hjust = 1)) 

# (iia) box_plots: player rating by genre
# note: observations have dependencies, genres are not independent observations
#       interpret with caution
ratingGenre <- longFromLogicals(myData, topGenres, c("player_rating", "multi_player"), key="genre")
ggplot(ratingGenre, aes(x=as.factor(genre), y=player_rating)) + 
  geom_boxplot(color="black", fill="blue") + 
  labs(title="Box Plot of Average Player Rating by Genre",
       x="Genre",
       y="Average Player Rating") + 
  scale_x_discrete(labels=genreNames)

# (iib) box_plots: player rating by genre, broken down by multiplayer
# note: observations have dependencies, genres are not independent observations
#       interpret with caution
ggplot(ratingGenre, aes(x=as.factor(genre), y=player_rating)) + 
  geom_boxplot(color="black", fill="blue") + 
  facet_wrap(multi_player~.) +
  labs(title="Box Plot of Average Player Rating by Genre",
       x="Genre",
       y="Average Player Rating") + 
  scale_x_discrete(labels=genreNames)

# (iii) scatterplot: of price x player_rating by (color) publisher
ggplot(myData, aes(x=player_rating, y=price)) + 
  geom_point(alpha=0.5) +
  geom_smooth(aes(group=publisher), method="lm") + 
  facet_wrap(~publisher) +
  labs(title="Scatterplot of Player Rating by Price by Publisher",
       x="Average Player Rating",
       y="Price")
  
# (iv) scatterplot: of price x player_rating by (panel/color) genre
# note: observations have dependencies, genres are not independent observations
#       interpret with caution
priceRatingGenre <- longFromLogicals(myData, topGenres, c("price", "player_rating"), key="genre")
ggplot(priceRatingGenre, aes(x=player_rating, y=price)) + 
  geom_point(aes(color=as.factor(genre)), alpha=0.3) + 
  labs(title="Scatterplot of Player Rating by Price by Genre",
       x="Average Player Rating",
       y="Price") + 
  scale_color_discrete(name="Genre",
                       labels=genreNames)

```

# Discussion

Analysis of multivariate associations with player ratings sought to determine what variables might have important or interesting associations with the perceptions consumers have on their video game purchases. From these plots several features appear to be worth mentioning: 

* There is very little apparent variation in player ratings by genre. Although one would expect not every genre to appeal to every player, this likely suggests that people who are purchasing video games tend to have a fairly good idea of what they will like and what they won't.  
* The breakdown by multi-player and genre shows an interesting feature where adventure games appear to have a noticeable drop-off compared to other categories. Since adventure games tend to be thematically single-player this could reflect the injection of a design choice into an incompatible genre.  
* In contrast to genre, there appears to be more significant variation in player rating by publisher. This makes sense as different publishers have different levels of resources and talent at their disposal. This evidence suggests this may make a significant impact on consumer satisfaction.  
* One result that seemed particularly surprising was a fairly flat (no strongly observed) association between pricing and player rating of the video game. It was expected that consumers might be harder on more expensive titles that don't reward as high quality of an experience and more lenient on cheaper budget titles. One hypothesis to explain the null finding is that the flat association could be evidence that GOG.com is setting price points efficiently in order to achieve the desired balance of profit to consumer satisfaction.  
* When broken down by genre, price, and player rating, role-playing games seem to have the highest level of variation in price and player rating (see scatter plot). In the combined scatterplot, there also appears to be some stronger evidence of a possible positive correlation between price and player rating. This potentially high variation may indicate the presence of other confounding variables which may obscure some relationship between price and player rating. 

Overall, the investigation into player rating (a surrogate measure of consumer satisfaction) was able to find at least one strong lead for further investigation. In particular, game publisher seemed to show the strongest variation with player rating and appears to so far be the strongest predictor worth investigating further. Potentially simple underlying explanations (e.g. differences in resources, talent) also make it an attractive starting point for further investigation.

Some ideas for further investigation could be to include video game date of publish, since the quality of video game publishers may change considerably over time. Also, GOG.com sells retro as well as modern games, which may have radically different flavors of consumer reception, so adding date data may help test hypotheses in this area as well. It may also be interesting to dig deeper into the genre and publisher associations with player ratings to see if publishers tend to do well in all genres they produce, or if they tend to perform particularly well in just one or two genres. Exploratory data analysis suggests that some publishers tend to specialize and therefore it is speculated that much of the between-publisher differences in player rating may occur in their areas of specialization. Finally, it is believe that further analysis could begin including all publishers from the original data set in order to provide further insights and possibly help resolve other potential interactions.